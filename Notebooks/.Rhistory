mode = "classification",
engine = "ranger",
importance = "impurity",
mtry = 5,
trees = 20,
min_n = 10
)
# Define our random forest model
rf_model <-
rand_forest(
mode = "classification",
engine = "ranger",
mtry = 5,
trees = 20,
min_n = 10
)
# Define our random forest model
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
#rf_model <-
# rand_forest(
#mode = "classification",
#engine = "ranger",
#mtry = 5,
#trees = 20,
#min_n = 10
#)
rf_mod <- rand_forest(mode = "regression", trees = 100) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(mtcars) %>%
extract_fit_parsnip() %>%
vip(num_features = 10)
rf_mod <- rand_forest(mode = "regression", trees = 100) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
extract_fit_parsnip() %>%
vip(num_features = 10)
rf_mod <- rand_forest(mode = "regression", trees = 100) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 10)
rf_mod <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 10)
rf_mod <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8)
rf_mod <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8, geom="point")
rf_mod <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_model) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
logistic_augment <-
augment(logistic_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
pred_df <- logistic_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_augment <-
augment(rf_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
rf_pred_df <- rf_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
# Area Under Curve (AUC)
rf_augment %>%
roc_auc(truth = as.factor(class), .pred_GALAXY)
accuracy(rf_pred_df, as.factor(class), as.factor(.pred_class))
head(rf_pred_df)
rf_pred_df
my_metrics <- metric_set(roc_auc, accuracy, sens, spec, precision, recall)
my_metrics
cv_folds <- vfold_cv(df_train, v = 5)
cv_folds <- vfold_cv(train_data, v = 5)
cv_folds
folds <- vfold_cv(train_data, v = 10)
folds
folds <- vfold_cv(train_data, v = 10)
rf_fit_rs <-
rf_workflow %>%
fit_resamples(folds)
rf_fit_rs
collect_metrics(rf_fit_rs)
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_model) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
rf_augment <-
augment(rf_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
rf_pred_df <- rf_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_pred_df
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
# Fit the model
rf_fit <-
rf_workflow %>%
fit(data = train_data)
rf_augment <-
augment(rf_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
rf_pred_df <- rf_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_pred_df
rf_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
# Fit the model
rf_fit <-
rf_workflow %>%
fit(data = train_data)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(GGally)
library(yardstick)
library(tidymodels)
library(skimr)
library(ranger)
library(vip)
# Import and view head of training data
path <- "../Data/Stellar-Classification-Dataset.csv"
raw_df <- read.csv(path)
# Make "Class" the first column
#reordered_raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
#head(reordered_raw_df)
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
head(raw_df)
# Filter the data by class and subsample
#galaxy_df <- reordered_raw_df[reordered_raw_df$class == "GALAXY", ]
#subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 1000, replace = FALSE),]
#qso_df <- reordered_raw_df[reordered_raw_df$class == "QSO", ]
#subsampled_qso_df <- qso_df[sample(nrow(qso_df), size = 1000, replace = FALSE),]
#star_df <- reordered_raw_df[reordered_raw_df$class == "STAR", ]
#subsampled_star_df <- star_df[sample(nrow(star_df), size = 1000, replace = FALSE),]
# Create new DataFrame
#new_df <- rbind(subsampled_galaxy_df, subsampled_qso_df, subsampled_star_df)
#head(new_df)
raw_df[raw_df == 'QSO' | raw_df == 'STAR'] <- 'OTHER'
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Filter the data by class and subsample
galaxy_df <- raw_df[raw_df$class == "GALAXY", ]
subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 40000, replace = FALSE),]
other_df <- raw_df[raw_df$class == "OTHER", ]
subsampled_other_df <- other_df[sample(nrow(other_df), size = 40000, replace = FALSE),]
# Create new DataFrame
df <- rbind(subsampled_galaxy_df, subsampled_other_df)
dim(df)
ggplot(df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Export data to .csv file
write.csv(df, "../Data/Binary-Subsampled-Data.csv", row.names=FALSE)
df %>%
skimr::skim(colnames(df))
set.seed(222)
# Put 80% of the data into the training set
data_split <- initial_split(df, prop = 0.8)
# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
# Declare the ID variables
IDs <- c("obj_ID", "run_ID", "rerun_ID", "cam_col", "field_ID", "spec_obj_ID", "plate", "MJD", "fiber_ID")
# Define our model, and exclude the ID variables
recipe <-
recipe(class ~ ., data = train_data) %>%
update_role(all_of(IDs), new_role = "ID")
# Summary of the recipe
summary(recipe)
# Define our logistic regression model
logistic_model <-
logistic_reg() %>%
set_engine("glm")
# Create our workflow
logistic_wflow <-
workflow() %>%
add_model(logistic_model) %>%
add_recipe(recipe)
logistic_wflow
# Fit the model
logistic_fit <-
logistic_wflow %>%
fit(data = train_data)
logistic_fit %>%
extract_fit_parsnip() %>%
tidy()
logistic_augment <-
augment(logistic_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
pred_df <- logistic_augment %>%
select(class, .pred_class, .pred_GALAXY)
pred_df
# Distribution of predictions
ggplot(pred_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
logistic_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
# Area Under Curve (AUC)
logistic_augment %>%
roc_auc(truth = as.factor(class), .pred_GALAXY)
accuracy(pred_df, as.factor(class), as.factor(.pred_class))
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_model) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
# Fit the model
rf_fit <-
rf_workflow %>%
fit(data = train_data)
rf_augment <-
augment(rf_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
rf_pred_df <- rf_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_pred_df
rf_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
# Area Under Curve (AUC)
rf_augment %>%
roc_auc(truth = as.factor(class), .pred_GALAXY)
accuracy(rf_pred_df, as.factor(class), as.factor(.pred_class))
folds <- vfold_cv(train_data, v = 10)
rf_random_samples <-
rf_workflow %>%
fit_resamples(folds)
rf_random_samples
collect_metrics(rf_random_samples)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(GGally)
library(yardstick)
library(tidymodels)
library(skimr)
library(ranger)
library(vip)
# Import and view head of training data
path <- "../Data/Stellar-Classification-Dataset.csv"
raw_df <- read.csv(path)
# Make "Class" the first column
#reordered_raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
#head(reordered_raw_df)
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
head(raw_df)
# Filter the data by class and subsample
#galaxy_df <- reordered_raw_df[reordered_raw_df$class == "GALAXY", ]
#subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 1000, replace = FALSE),]
#qso_df <- reordered_raw_df[reordered_raw_df$class == "QSO", ]
#subsampled_qso_df <- qso_df[sample(nrow(qso_df), size = 1000, replace = FALSE),]
#star_df <- reordered_raw_df[reordered_raw_df$class == "STAR", ]
#subsampled_star_df <- star_df[sample(nrow(star_df), size = 1000, replace = FALSE),]
# Create new DataFrame
#new_df <- rbind(subsampled_galaxy_df, subsampled_qso_df, subsampled_star_df)
#head(new_df)
raw_df[raw_df == 'QSO' | raw_df == 'STAR'] <- 'OTHER'
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Filter the data by class and subsample
galaxy_df <- raw_df[raw_df$class == "GALAXY", ]
subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 40000, replace = FALSE),]
other_df <- raw_df[raw_df$class == "OTHER", ]
subsampled_other_df <- other_df[sample(nrow(other_df), size = 40000, replace = FALSE),]
# Create new DataFrame
df <- rbind(subsampled_galaxy_df, subsampled_other_df)
dim(df)
ggplot(df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Export data to .csv file
write.csv(df, "../Data/Binary-Subsampled-Data.csv", row.names=FALSE)
df %>%
skimr::skim(colnames(df))
set.seed(222)
# Put 80% of the data into the training set
data_split <- initial_split(df, prop = 0.8)
# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
# Declare the ID variables
IDs <- c("obj_ID", "run_ID", "rerun_ID", "cam_col", "field_ID", "spec_obj_ID", "plate", "MJD", "fiber_ID")
# Define our model, and exclude the ID variables
recipe <-
recipe(class ~ ., data = train_data) %>%
update_role(all_of(IDs), new_role = "ID")
# Summary of the recipe
summary(recipe)
# Define our logistic regression model
logistic_model <-
logistic_reg() %>%
set_engine("glm")
# Create our workflow
logistic_wflow <-
workflow() %>%
add_model(logistic_model) %>%
add_recipe(recipe)
logistic_wflow
# Fit the model
logistic_fit <-
logistic_wflow %>%
fit(data = train_data)
logistic_fit %>%
extract_fit_parsnip() %>%
tidy()
logistic_augment <-
augment(logistic_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
pred_df <- logistic_augment %>%
select(class, .pred_class, .pred_GALAXY)
pred_df
# Distribution of predictions
ggplot(pred_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
logistic_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
# Area Under Curve (AUC)
logistic_augment %>%
roc_auc(truth = as.factor(class), .pred_GALAXY)
accuracy(pred_df, as.factor(class), as.factor(.pred_class))
rf_model <- rand_forest(mode = "classification", trees = 20) %>%
set_engine("ranger", importance = "impurity")
rf_workflow <-
workflow() %>%
add_model(rf_model) %>%
add_recipe(recipe)
rf_workflow %>%
fit(df) %>%
extract_fit_parsnip() %>%
vip(num_features = 8) +
labs(title = "Random forest variable importance")
# Fit the model
rf_fit <-
rf_workflow %>%
fit(data = train_data)
rf_augment <-
augment(rf_fit, test_data, type = "prob")
# DataFrame of prediction probabilities
rf_pred_df <- rf_augment %>%
select(class, .pred_class, .pred_GALAXY)
rf_pred_df
rf_augment %>%
roc_curve(truth = as.factor(class), .pred_GALAXY) %>%
autoplot()
# Area Under Curve (AUC)
rf_augment %>%
roc_auc(truth = as.factor(class), .pred_GALAXY)
accuracy(rf_pred_df, as.factor(class), as.factor(.pred_class))
folds <- vfold_cv(train_data, v = 10)
rf_random_samples <-
rf_workflow %>%
fit_resamples(folds)
rf_random_samples
collect_metrics(rf_random_samples)
plot(rf_fit)
summary(rf_fit)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(GGally)
library(yardstick)
library(tidymodels)
library(skimr)
library(ranger)
library(vip)
# Import and view head of training data
path <- "../Data/Stellar-Classification-Dataset.csv"
raw_df <- read.csv(path)
# Make "Class" the first column
#reordered_raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
#head(reordered_raw_df)
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
raw_df <- raw_df[,c(14,1:13, 15:ncol(raw_df))]
head(raw_df)
# Filter the data by class and subsample
#galaxy_df <- reordered_raw_df[reordered_raw_df$class == "GALAXY", ]
#subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 1000, replace = FALSE),]
#qso_df <- reordered_raw_df[reordered_raw_df$class == "QSO", ]
#subsampled_qso_df <- qso_df[sample(nrow(qso_df), size = 1000, replace = FALSE),]
#star_df <- reordered_raw_df[reordered_raw_df$class == "STAR", ]
#subsampled_star_df <- star_df[sample(nrow(star_df), size = 1000, replace = FALSE),]
# Create new DataFrame
#new_df <- rbind(subsampled_galaxy_df, subsampled_qso_df, subsampled_star_df)
#head(new_df)
raw_df[raw_df == 'QSO' | raw_df == 'STAR'] <- 'OTHER'
ggplot(raw_df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Filter the data by class and subsample
galaxy_df <- raw_df[raw_df$class == "GALAXY", ]
subsampled_galaxy_df <- galaxy_df[sample(nrow(galaxy_df), size = 40000, replace = FALSE),]
other_df <- raw_df[raw_df$class == "OTHER", ]
subsampled_other_df <- other_df[sample(nrow(other_df), size = 40000, replace = FALSE),]
# Create new DataFrame
df <- rbind(subsampled_galaxy_df, subsampled_other_df)
dim(df)
ggplot(df,aes(x=factor(class))) +
geom_bar() +
labs(title="Counts of Class Column", x="Class", y = "Count")+
geom_text(aes(label=..count..),stat='count', vjust=-0.2)
# Export data to .csv file
write.csv(df, "../Data/Binary-Subsampled-Data.csv", row.names=FALSE)
